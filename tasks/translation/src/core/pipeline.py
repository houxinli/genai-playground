#!/usr/bin/env python3
"""
ç¿»è¯‘æµç¨‹æ§åˆ¶æ¨¡å—
"""

import time
from pathlib import Path
from typing import List, Tuple, Dict, Optional

from .config import TranslationConfig
from .logger import UnifiedLogger
from .quality_checker import QualityChecker
from .translator import Translator
from .file_handler import FileHandler


class TranslationPipeline:
    """ç¿»è¯‘æµç¨‹æ§åˆ¶ç±»"""
    
    def __init__(self, config: TranslationConfig):
        """
        åˆå§‹åŒ–ç¿»è¯‘æµç¨‹
        
        Args:
            config: ç¿»è¯‘é…ç½®
        """
        self.config = config
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.logger = UnifiedLogger.create_console_only()
        self.quality_checker = QualityChecker(config, self.logger)
        self.translator = Translator(config, self.logger, self.quality_checker)
        self.file_handler = FileHandler(config, self.logger, self.quality_checker)
    
    def run(self, inputs: List[str]) -> int:
        """
        è¿è¡Œç¿»è¯‘æµç¨‹
        
        Args:
            inputs: è¾“å…¥æ–‡ä»¶/ç›®å½•åˆ—è¡¨
            
        Returns:
            æˆåŠŸå¤„ç†çš„æ–‡ä»¶æ•°é‡
        """
        # éªŒè¯é…ç½®
        errors = self.config.validate()
        if errors:
            for error in errors:
                self.logger.error(f"é…ç½®é”™è¯¯: {error}")
            return 0
        
        # æŸ¥æ‰¾æ–‡ä»¶
        files_to_process = self.file_handler.find_files_to_process(inputs)
        
        if not files_to_process:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶")
            return 0
        
        self.logger.info(f"å¼€å§‹å¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶")
        
        # åº”ç”¨é™åˆ¶
        if self.config.limit > 0:
            files_to_process = files_to_process[:self.config.limit]
            self.logger.info(f"é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡ä¸º: {len(files_to_process)}")
        
        # å¤„ç†æ–‡ä»¶
        success_count = 0
        for i, file_path in enumerate(files_to_process, 1):
            self.logger.info(f"å¤„ç†æ–‡ä»¶ {i}/{len(files_to_process)}: {file_path}")
            
            # åœ¨æ˜¾å¼è°ƒè¯•æ¨¡å¼ä¸‹é™åˆ¶é‡è¯•æ¬¡æ•°ä»¥åŠ å¿«è¿­ä»£
            if getattr(self.config, 'debug', False):
                if self.config.retries > 1:
                    self.logger.info("è°ƒè¯•æ¨¡å¼ä¸‹å°†é‡è¯•æ¬¡æ•°é™åˆ¶ä¸º 1")
                    self.config.retries = 1

            if self.process_file(file_path):
                success_count += 1
            else:
                self.logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {file_path}")
        
        self.logger.info(f"å¤„ç†å®Œæˆ: {success_count}/{len(files_to_process)} ä¸ªæ–‡ä»¶æˆåŠŸ")
        return success_count
    
    def process_file(self, path: Path) -> bool:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            path: æ–‡ä»¶è·¯å¾„
        
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        # è®¾ç½®æ—¥å¿—
        log_file_path = None
        if self.config.realtime_log:
            # æ–‡ä»¶æ—¥å¿— + æ§åˆ¶å°è¾“å‡ºç”±è‡ªå®šä¹‰ _emit æ‰“å°ï¼Œé¿å… handler å†æ¬¡æ‰“å°å¯¼è‡´é‡å¤
            self.logger = UnifiedLogger.create_for_file(path, self.config.log_dir, stream_output=False)
            self.translator.logger = self.logger
            self.file_handler.logger = self.logger
            # åŒæ­¥æ›´æ–°è´¨é‡æ£€æµ‹ä¸æµå¼å¤„ç†å™¨ä¸Šçš„loggerï¼Œé¿å…æ§åˆ¶å°é‡å¤è°ƒè¯•è¾“å‡º
            if hasattr(self.quality_checker, 'logger'):
                self.quality_checker.logger = self.logger
            if hasattr(self.translator, 'streaming_handler') and self.translator.streaming_handler:
                self.translator.streaming_handler.logger = self.logger
            if hasattr(self.quality_checker, 'streaming_handler') and self.quality_checker.streaming_handler:
                self.quality_checker.streaming_handler.logger = self.logger
            # è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„
            log_file_path = self.logger.get_log_file_path()
            self.logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {path}")
            self.logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_file_path}")
        else:
            self.logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {path}")
        
        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        self._log_config_info()
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            self.logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return False
        
        # è§£æYAML front matter
        yaml_data, text_content = self._parse_yaml_front_matter(content)
        
        # æ˜¾ç¤ºæ–‡ç« ä¿¡æ¯
        self._log_article_info(yaml_data, len(text_content))
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_path = self._get_output_path(path)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
        if not self.config.overwrite and output_path.exists():
            self.logger.info(f"è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_path}")
            return True
        
        # ç¿»è¯‘æ–‡æœ¬
        translated_content = self._translate_text(text_content)
        
        if not translated_content:
            self.logger.error("ç¿»è¯‘å¤±è´¥")
            return False
        
        # ä¿å­˜ç»“æœ
        return self._save_result(output_path, translated_content, yaml_data)
    
    def _log_config_info(self) -> None:
        """è®°å½•é…ç½®ä¿¡æ¯"""
        self.logger.info("ğŸ”§ ç¿»è¯‘é…ç½®:")
        self.logger.info(f"   æ¨¡å‹: {self.config.model}")
        self.logger.info(f"   æ¨¡å¼: {self.config.mode}")
        self.logger.info(f"   å¯¹ç…§æ¨¡å¼: {self.config.bilingual}")
        self.logger.info(f"   æµå¼è¾“å‡º: {self.config.stream}")
        self.logger.info(f"   å®æ—¶æ—¥å¿—: {self.config.realtime_log}")
        self.logger.info(f"   å—å¤§å°: {self.config.chunk_size_chars} å­—ç¬¦")
        self.logger.info(f"   é‡å å¤§å°: {self.config.overlap_chars} å­—ç¬¦")
        self.logger.info(f"   é‡è¯•æ¬¡æ•°: {self.config.retries}")
        self.logger.info(f"   é‡è¯•ç­‰å¾…: {self.config.retry_wait} ç§’")
        self.logger.info(f"   ä¸Šä¸‹æ–‡é•¿åº¦: {self.config.get_max_context_length()}")
        self.logger.info(f"   æ¸©åº¦: {self.config.temperature}")
        self.logger.info(f"   é¢‘ç‡æƒ©ç½š: {self.config.frequency_penalty}")
        self.logger.info(f"   å­˜åœ¨æƒ©ç½š: {self.config.presence_penalty}")
        self.logger.info(f"   æœ¯è¯­æ–‡ä»¶: {self.config.terminology_file}")
        self.logger.info(f"   ç¤ºä¾‹æ–‡ä»¶: {self.config.sample_file}")
        self.logger.info(f"   å‰è¨€æ–‡ä»¶: {self.config.preface_file}")
        self.logger.info(f"   åœæ­¢è¯: {self.config.stop}")
        self.logger.info(f"   æ—¥å¿—ç›®å½•: {self.config.log_dir}")
        self.logger.info("   ==================================================")
    
    def _parse_yaml_front_matter(self, content: str) -> Tuple[Optional[Dict], str]:
        """è§£æYAML front matter"""
        if not content.startswith('---'):
            return None, content
        
        try:
            import yaml
            parts = content.split('---', 2)
            if len(parts) < 3:
                return None, content
            
            yaml_content = parts[1].strip()
            text_content = parts[2].strip()
            
            yaml_data = yaml.safe_load(yaml_content)
            return yaml_data, text_content
        except:
            return None, content
    
    def _log_article_info(self, yaml_data: Optional[Dict], text_length: int) -> None:
        """è®°å½•æ–‡ç« ä¿¡æ¯"""
        self.logger.info("ğŸ“– æ–‡ç« ä¿¡æ¯:")
        
        if yaml_data:
            self.logger.info(f"   æ ‡é¢˜: {yaml_data.get('title', 'N/A')}")
            self.logger.info(f"   ä½œè€…: {yaml_data.get('author', {}).get('name', 'N/A')}")
            self.logger.info(f"   ç³»åˆ—: {yaml_data.get('series', {}).get('title', 'N/A')}")
            self.logger.info(f"   åˆ›å»ºæ—¶é—´: {yaml_data.get('create_date', 'N/A')}")
            tags = yaml_data.get('tags', [])
            if tags:
                self.logger.info(f"   æ ‡ç­¾: {', '.join(tags)}")
        
        self.logger.info(f"   åŸæ–‡é•¿åº¦: {text_length} å­—ç¬¦")
    
    def _get_output_path(self, input_path: Path) -> Path:
        """è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
        stem = input_path.stem
        suffix = self.config.get_output_suffix()
        return input_path.parent / f"{stem}{suffix}.txt"
    
    def _translate_text(self, text_content: str) -> str:
        """ç¿»è¯‘æ–‡æœ¬å†…å®¹"""
        max_ctx = self.config.get_max_context_length()
        estimated_input_tokens = len(text_content) // 2
        margin = 2000
        # åœ¨åŒè¯­æ¨¡å¼ä¸‹æ›´ç§¯æåœ°åˆ†å—ï¼Œé¿å…è¾“å‡ºè¢«æˆªæ–­
        bilingual_long = self.config.bilingual and len(text_content) > 8000
        need_chunk = (
            self.config.mode == "chunked"
            or estimated_input_tokens > (max_ctx - margin)
            or len(text_content) > self.config.chunk_size_chars
            or bilingual_long
        ) or (self.config.bilingual and len(text_content) > 6000)

        if need_chunk:
            self.logger.info("è¾“å…¥è¾ƒé•¿ï¼Œå¯ç”¨åˆ†å—ç¿»è¯‘â€¦")
            # ä¸ºä¿è¯åŒè¯­å……è¶³è¾“å‡ºï¼Œè¿›ä¸€æ­¥ç¼©å°å•å—é•¿åº¦ï¼Œé¿å…ä¸Šä¸‹æ–‡æº¢å‡ºä¸è¾“å‡ºæˆªæ–­
            if self.config.bilingual:
                chunk_size = 3000
                overlap = max(0, min(self.config.overlap_chars, 400)) or 400
            else:
                chunk_size = min(self.config.chunk_size_chars, 8000)
                overlap = max(0, self.config.overlap_chars)
            chunks = []
            start = 0
            n = len(text_content)
            while start < n:
                end = min(n, start + chunk_size)
                chunk = text_content[start:end]
                chunks.append(chunk)
                if end >= n:
                    break
                start = end - overlap if overlap > 0 else end

            results: list[str] = []
            for idx, chunk in enumerate(chunks, 1):
                self.logger.info(f"ç¿»è¯‘åˆ†å— {idx}/{len(chunks)}ï¼Œé•¿åº¦: {len(chunk)}")
                result, prompt, success, token_meta = self.translator.translate_text(chunk, chunk_index=idx)
                if not success or not result:
                    self.logger.warning(f"åˆ†å— {idx} ç¿»è¯‘å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ä»¥ç»§ç»­æ‹¼æ¥")
                    result = ""
                else:
                    self.logger.info(f"Tokenä½¿ç”¨æƒ…å†µ: {token_meta}")
                results.append(result)
            return "\n".join(results)

        # ä¸éœ€è¦åˆ†å—ï¼Œç›´æ¥å•å—ç¿»è¯‘
        result, prompt, success, token_meta = self.translator.translate_text(text_content)
        if not success:
            self.logger.error("ç¿»è¯‘å¤±è´¥")
            return ""
        self.logger.info(f"Tokenä½¿ç”¨æƒ…å†µ: {token_meta}")
        return result
    
    def _save_result(self, output_path: Path, content: str, yaml_data: Optional[Dict]) -> bool:
        """ä¿å­˜ç¿»è¯‘ç»“æœ"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.logger.info(f"WRITE {output_path}")
            
            # è®°å½•æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœå¯ç”¨äº†å®æ—¶æ—¥å¿—ï¼‰
            if self.config.realtime_log and hasattr(self.logger, 'get_log_file_path'):
                log_file_path = self.logger.get_log_file_path()
                if log_file_path:
                    self.logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_file_path}")
            
            return True
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return False
