#!/usr/bin/env python3
"""
vLLM çŠ¶æ€æ£€æŸ¥å·¥å…·
ä½¿ç”¨ localhost API æ£€æŸ¥æœåŠ¡çŠ¶æ€
"""

import requests
import json
import sys
import time

def check_vllm_status():
    """æ£€æŸ¥vLLMæœåŠ¡çŠ¶æ€"""
    try:
        # æ£€æŸ¥æ¨¡åž‹åˆ—è¡¨
        response = requests.get("http://localhost:8000/v1/models", timeout=5)
        
        if response.status_code == 200:
            models = response.json()
            print("âœ… vLLM æœåŠ¡æ­£åœ¨è¿è¡Œ")
            print(f"ðŸ“Š ç«¯å£: 8000")
            print(f"ðŸ“¦ å¯ç”¨æ¨¡åž‹:")
            
            for model in models.get('data', []):
                print(f"  - {model['id']}")
                print(f"    æœ€å¤§é•¿åº¦: {model.get('max_model_len', 'N/A')}")
                print(f"    åˆ›å»ºæ—¶é—´: {model.get('created', 'N/A')}")
            
            return True
        else:
            print(f"âŒ vLLM æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿žæŽ¥åˆ° vLLM æœåŠ¡ (localhost:8000)")
        print("ðŸ’¡ è¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²å¯åŠ¨")
        return False
    except requests.exceptions.Timeout:
        print("âŒ è¿žæŽ¥ vLLM æœåŠ¡è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥çŠ¶æ€æ—¶å‡ºé”™: {e}")
        return False

def wait_for_service(max_wait=300):
    """ç­‰å¾…æœåŠ¡å¯åŠ¨"""
    print(f"â³ ç­‰å¾… vLLM æœåŠ¡å¯åŠ¨ (æœ€å¤š {max_wait} ç§’)...")
    
    for i in range(max_wait):
        if check_vllm_status():
            print("ðŸŽ‰ æœåŠ¡å·²å°±ç»ªï¼")
            return True
        
        if i % 10 == 0:
            print(f"â³ å·²ç­‰å¾… {i} ç§’...")
        
        time.sleep(1)
    
    print("â° ç­‰å¾…è¶…æ—¶ï¼ŒæœåŠ¡å¯èƒ½å¯åŠ¨å¤±è´¥")
    return False

def main():
    if len(sys.argv) > 1 and sys.argv[1] == "wait":
        wait_for_service()
    else:
        check_vllm_status()

if __name__ == "__main__":
    main()
